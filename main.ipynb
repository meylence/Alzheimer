{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from random import shuffle\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cuda\")\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda:0\")\n",
    "    print(\"Training on GPU... Ready for HyperJump...\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Training on CPU... May the force be with you...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'dataset/'\n",
    "print(\"DATA_PATH = \",DATA_PATH)\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, \"train/\")\n",
    "print(\"TRAIN_PATH = \", TRAIN_PATH)\n",
    "\n",
    "VAL_PATH = os.path.join(DATA_PATH, \"test/\")\n",
    "print(\"TEST_PATH = \",VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = os.listdir(DATA_PATH)\n",
    "class_name_train = os.listdir(TRAIN_PATH)\n",
    "class_name_val = os.listdir(VAL_PATH)\n",
    "image_count_train = {}\n",
    "image_count_val = {}\n",
    "\n",
    "for i in class_name_train:\n",
    "    image_count_train[i] = len(os.listdir(os.path.join(TRAIN_PATH,i)))\n",
    "    \n",
    "for i in class_name_val:\n",
    "    image_count_val[i] = len(os.listdir(os.path.join(VAL_PATH,i)))\n",
    "\n",
    "# print(image_count_train)\n",
    "\n",
    "sum_train_images = 0\n",
    "for k,v in image_count_train.items():\n",
    "    sum_train_images += v\n",
    "\n",
    "# print(sum_train_images)\n",
    "\n",
    "sum_val_images = 0\n",
    "for k,v in image_count_val.items():\n",
    "     sum_val_images += v\n",
    "\n",
    "# print(sum_val_images)\n",
    "\n",
    "image_count = {'train': sum_train_images, 'test': sum_val_images}\n",
    "\n",
    "#Plotting Distribution of Each Classes\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 10), subplot_kw=dict(aspect=\"equal\"))\n",
    "ax1.pie(image_count.values(),\n",
    "        labels = image_count.keys(),\n",
    "        shadow=True,\n",
    "        autopct = '%1.1f%%',\n",
    "        startangle=90)\n",
    "plt.title(\"Eğitim ve Test Dağılım Grafiği\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(TRAIN_PATH)\n",
    "image_count = {}\n",
    "for i in class_names:\n",
    "    image_count[i] = len(os.listdir(os.path.join(TRAIN_PATH,i)))\n",
    "\n",
    "#Plotting Distribution of Each Classes\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 10), subplot_kw=dict(aspect=\"equal\"))\n",
    "ax1.pie(image_count.values(),\n",
    "        labels = image_count.keys(),\n",
    "        shadow=True,\n",
    "        autopct = '%1.1f%%',\n",
    "        startangle=90)\n",
    "plt.title(\"Eğitim Verisi Sınıf Dağılım Grafiği\")\n",
    "plt.show()\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(VAL_PATH)\n",
    "image_count = {}\n",
    "for i in class_names:\n",
    "    image_count[i] = len(os.listdir(os.path.join(VAL_PATH,i)))\n",
    "\n",
    "#Plotting Distribution of Each Classes\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 10), subplot_kw=dict(aspect=\"equal\"))\n",
    "ax1.pie(image_count.values(),\n",
    "        labels = image_count.keys(),\n",
    "        shadow=True,\n",
    "        autopct = '%1.1f%%',\n",
    "        startangle=90)\n",
    "plt.title(\"Test Verisi Sınıf Dağılım Grafiği\")\n",
    "plt.show()\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics Based on ImageNet Data for Normalisation\n",
    "mean_nums = [0.485, 0.456, 0.406]\n",
    "std_nums = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transforms = {\"train\":transforms.Compose([\n",
    "                                transforms.Resize((128,128)), #Resizes all images into same dimension\n",
    "                                transforms.ToTensor(), # Coverts into Tensors\n",
    "                                transforms.Normalize(mean = mean_nums, std=std_nums)]), # Normalizes\n",
    "                    \"test\": transforms.Compose([\n",
    "                                transforms.Resize((128,128)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=mean_nums, std = std_nums)\n",
    "                    ])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test(datadir, valid_size = .3):\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=data_transforms['train']) #Picks up Image Paths from its respective folders and label them\n",
    "    print(train_data)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=data_transforms['test'])\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    dataset_size = {\"train\":len(train_idx), \"val\":len(test_idx)}\n",
    "    train_sampler = SubsetRandomSampler(train_idx) # Sampler for splitting train and val images\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=16) # DataLoader provides data from traininng and validation in batches\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=16)\n",
    "    return trainloader, testloader, dataset_size\n",
    "trainloader, valloader, dataset_size = load_split_train_test(TRAIN_PATH, .3)\n",
    "dataloaders = {\"train\":trainloader, \"val\":valloader}\n",
    "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
    "class_names = trainloader.dataset.classes\n",
    "print(data_sizes)\n",
    "print(class_names)\n",
    "\n",
    "# Dataset has 15886 data points.\n",
    "# Train Dataset has 12708 data points\n",
    "# Test Dataset has 3178 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def imshow(inp, size =(40,40), title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = mean_nums\n",
    "    std = std_nums\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, size=30)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs, nrow =  4, padding =  2, value_range = 1)\n",
    "\n",
    "\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "\n",
    "# # Get a batch of val data\n",
    "\n",
    "# inputs, classes = next(iter(dataloaders['val']))\n",
    "\n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model(pretrained=True):\n",
    "    model = models.densenet121(pretrained=pretrained) # Returns Defined Densenet model with weights trained on ImageNet\n",
    "    #model = models.resnet(pretrained=pretrained)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = CNN_Model(pretrained=True)\n",
    "\n",
    "# specify loss function (categorical cross-entropy loss)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Specify optimizer which performs Gradient Descent\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=429, gamma=0.1) # Learning Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "            current_kappa = 0\n",
    "            val_kappa = list()\n",
    "\n",
    "            for inputs, labels in tqdm.tqdm(dataloaders[phase], desc=phase, leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # We need to zero the gradients in the Cache.\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Time to carry out the forward training poss\n",
    "                # We only need to log the loss stats if we are in training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                # We want variables to hold the loss statistics\n",
    "                current_loss += loss.item() * inputs.size(0)\n",
    "                current_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                val_kappa.append(cohen_kappa_score(preds.cpu().numpy(), labels.data.cpu().numpy()))\n",
    "                #print(val_kappa)\n",
    "            epoch_loss = current_loss / data_sizes[phase]\n",
    "            epoch_acc = current_corrects.double() / data_sizes[phase]\n",
    "            if phase == 'val':\n",
    "                epoch_kappa = np.mean(val_kappa)\n",
    "                print('{} Loss: {:.4f} | {} Accuracy: {:.4f} | Kappa Score: {:.4f}'.format(\n",
    "                    phase, epoch_loss, phase, epoch_acc, epoch_kappa))\n",
    "            else:\n",
    "                print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(\n",
    "                    phase, epoch_loss, phase, epoch_acc))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('Val loss Decreased from {:.4f} to {:.4f} \\nSaving Weights... '.format(best_loss, epoch_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_since = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_since // 60, time_since % 60))\n",
    "    print('Best val loss: {:.4f}'.format(best_loss))\n",
    "\n",
    "    # Now we'll load in the best model weights and return it\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "base_model = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"deneme2.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=12):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_handeled = 0\n",
    "    ax = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_handeled += 1    \n",
    "                ax = plt.subplot(num_images//2, 2, images_handeled)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('Actual: {} Predicted: {}'.format(class_names[labels[j].item()],class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j], (16,4))\n",
    "\n",
    "                if images_handeled == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(base_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def test_model(model,dataloaders,device):\n",
    "    CM=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #for data in dataloaders['test']:\n",
    "        i=0\n",
    "        j=0\n",
    "        sumtp, sumfp, sumfn, sumfp = 0, 0, 0, 0\n",
    "        for data in dataloaders['val']:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) #file_name\n",
    "            preds = torch.argmax(outputs.data, 1)\n",
    "            CM+=confusion_matrix(labels.cpu(), preds.cpu(),labels=[0, 1 ])\n",
    "\n",
    "        tp=CM[1][1]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        acc=np.sum(np.diag(CM)/np.sum(CM))\n",
    "        recall=sumtp/(sumtp+sumfn)\n",
    "        precision=sumtp/(sumtp+sumfp)\n",
    "        print('\\nTestset Accuracy(mean): %f %%' % (100 * acc))\n",
    "        #print('- NPV: ',(tn/(tn+fn))*100\n",
    "        return acc, CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, cm = test_model(model,dataloaders,device)\n",
    "print(cm)\n",
    "print(\"Accuracy\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "plot_confusion_matrix(cm, target_names= ['NORMAL', 'PNEUMONIA'], title='Confusion matrix' , normalize=False)    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b37249c2f90de583471972dc3851a15602fac0d2a32d2557ecae04596749ca7b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
